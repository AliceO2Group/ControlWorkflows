name: readout-dataflow
defaults:
  roc_ctp_emulator_enabled: "false"
  dd_enabled: "true"
  ddsched_enabled: "false"
  dcs_enabled: "false"
  qcdd_enabled: "false" # qcdd_enabled and minimal_dpl_enabled cannot be both true!
  minimal_dpl_enabled: "false"
  dpl_workflow: "none" # if specified, we use dpl_worfklow to choose what is between STFB and STFS. Otherwise, we fall to the old choice mechanism.
                       # available options: "none", "qc-daq", "minimal-dpl", "tof-compressor", "hmpid-raw-qc"
  stfb_standalone: "false"
  odc_enabled: "false"
  odcshim_enabled: "false"
  roc_cleanup_enabled: "true"
  fmq_cleanup_enabled: "true"
  monitoring_dpl_url: "no-op://"
  monitoring_qc_url: "no-op://"
  monitoring_dd_url: "no-op://"
  monitoring_readout_url: "no-op://"
  detector: TST
  user: flp
  log_task_output: none
  fmq_rate_logging: "10"
roles:
  - name: host-{{ it }}
    for:
      range: "{{ hosts }}"
      var: it
    vars:
      readout_cfg_uri_standalone: "consul-ini://{{ consul_endpoint }}/o2/components/readout/ANY/any/readout-standalone-{{ it }}"
      readout_cfg_uri_stfb: "consul-ini://{{ consul_endpoint }}/o2/components/readout/ANY/any/readout-stfb-{{ it }}"
      dd_discovery_ib_hostname: "{{ it }}-ib" # MUST be defined for all stfb and stfs
    constraints:
      - attribute: machine_id
        value: "{{ it }}"
    roles:
      - name: "readout"
        vars:
          readout_cfg_uri: '{{dd_enabled == "true" ? readout_cfg_uri_stfb : readout_cfg_uri_standalone}}'
        task:
          load: readout
      - name: "data-distribution"
        enabled: "{{dd_enabled == 'true' && (qcdd_enabled == 'false' && minimal_dpl_enabled == 'false' && dpl_workflow == 'none')}}"
        roles:
          - name: "stfb-standalone"
            enabled: "{{stfb_standalone}}"
            connect:
              - name: readout
                type: pull
                target: "{{ Up(2).Path }}.readout:readout"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfbuilder-nooutput
          - name: "stfb"
            enabled: "{{stfb_standalone == 'false'}}"
            vars:
              dd_discovery_stfb_id: stfb-{{ it }}-{{ NewID() }} # must be defined for all stfb roles
            connect:
              - name: readout
                type: pull
                target: "{{ Up(2).Path }}.readout:readout"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfbuilder-senderoutput
          - name: "stfs"
            enabled: "{{stfb_standalone == 'false'}}"
            vars:
              dd_discovery_stfs_id: stfs-{{ it }}-{{ NewID() }} # must be defined for all stfs roles
              stfs_input_channel_name: buildertosender
            connect:
              - name: buildertosender
                type: pull
                target: "{{ Parent().Path }}.stfb:buildertosender"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfsender
      - name: "data-distribution-dpl"
        enabled: "{{(qcdd_enabled == 'true' || minimal_dpl_enabled == 'true' || dpl_workflow != 'none') && dd_enabled == 'true'}}"
        defaults:
          path_to_readout_proxy: "{{ Parent().Path }}.data-distribution-dpl.stfb:dpl-chan"
        roles:
          - name: "stfb"
            enabled: "{{stfb_standalone == 'false'}}"
            vars:
              dd_discovery_stfb_id: stfb-{{ it }}-{{ NewID() }}
            connect:
              - name: readout
                type: pull
                target: "{{ Up(2).Path }}.readout:readout"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              #NOTE: plain stfbuilder TT (not stfbuilder-senderoutput) because we want dpl-chan
              load: stfbuilder
          - name: "stfs"
            enabled: "{{stfb_standalone == 'false' && qcdd_enabled == 'true'}}"
            vars:
              dd_discovery_stfs_id: stfs-{{ it }}-{{ NewID() }}
              stfs_input_channel_name: downstream
            connect:
              - name: downstream
                type: pull
                target: "{{ Parent().Path }}.qc-daq.dpl-output-proxy:downstream"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfsender
          - name: "stfs"
            enabled: "{{stfb_standalone == 'false' && minimal_dpl_enabled == 'true'}}"
            vars:
              dd_discovery_stfs_id: stfs-{{ it }}-{{ NewID() }}
              stfs_input_channel_name: downstream
            connect:
              - name: downstream
                type: pull
                target: "{{ Parent().Path }}.minimal-dpl-wf.dpl-output-proxy:downstream" # we need some automatic way to find out the wf+task name
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfsender
          - name: "stfs" # this stfs is for any DPL workflow. We assume that it has a device dpl-output-proxy and a downstream channel
            enabled: "{{stfb_standalone == 'false' && minimal_dpl_enabled == 'false' && qcdd_enabled == 'false' && dpl_workflow != 'none'}}"
            vars:
              dd_discovery_stfs_id: stfs-{{ it }}-{{ NewID() }}
              stfs_input_channel_name: downstream
            connect:
              - name: downstream
                type: pull
                target: "{{ Parent().Path }}.{{ dpl_workflow }}.dpl-output-proxy:downstream"
                rateLogging: "{{ fmq_rate_logging }}"
            task:
              load: stfsender
          - name: qc-daq
            enabled: "{{ qcdd_enabled == 'true' || dpl_workflow == 'qc-daq' }}"
            defaults:
              dpl_config: "/etc/flp.d/qc/stfb-qc.dpl.json"
            vars:
              qc_config_uri: consul-json://{{ consul_endpoint }}/o2/components/qc/ANY/any/stfb_to_daqtask-{{ it }}
            roles:
              - name: "internal-dpl-clock"
                connect:
                task:
                  load: stfb-qc-internal-dpl-clock
              - name: "readout-proxy"
                connect:
                - name: from_internal-dpl-clock_to_readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_readout-proxy"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Up(2).Path }}.stfb:dpl-chan"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-readout-proxy
              - name: "dpl-output-proxy"
                connect:
                - name: from_readout-proxy_to_dpl-output-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.readout-proxy:from_readout-proxy_to_dpl-output-proxy"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-dpl-output-proxy
              - name: "Dispatcher"
                connect:
                - name: from_internal-dpl-clock_to_Dispatcher
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_Dispatcher"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: from_dpl-output-proxy_to_Dispatcher
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.dpl-output-proxy:from_dpl-output-proxy_to_Dispatcher"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-Dispatcher
              - name: "QC-TASK-RUNNER-dataDistribution"
                connect:
                - name: from_internal-dpl-clock_to_QC-TASK-RUNNER-dataDistribution
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_QC-TASK-RUNNER-dataDistribution"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: from_Dispatcher_to_QC-TASK-RUNNER-dataDistribution
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.Dispatcher:from_Dispatcher_to_QC-TASK-RUNNER-dataDistribution"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-QC-TASK-RUNNER-dataDistribution
              - name: "QC-CHECK-RUNNER-QcCheck"
                connect:
                - name: from_QC-TASK-RUNNER-dataDistribution_to_QC-CHECK-RUNNER-QcCheck
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.QC-TASK-RUNNER-dataDistribution:from_QC-TASK-RUNNER-dataDistribution_to_QC-CHECK-RUNNER-QcCheck"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-QC-CHECK-RUNNER-QcCheck
              - name: "internal-dpl-global-binary-file-sink"
                connect:
                - name: from_QC-CHECK-RUNNER-QcCheck_to_internal-dpl-global-binary-file-sink
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.QC-CHECK-RUNNER-QcCheck:from_QC-CHECK-RUNNER-QcCheck_to_internal-dpl-global-binary-file-sink"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: stfb-qc-internal-dpl-global-binary-file-sink
          - name: minimal-dpl-wf
            enabled: "{{  minimal_dpl_enabled == 'true' || dpl_workflow == 'minimal-dpl' }}"
            defaults:
              dpl_config: "/etc/flp.d/minimal-dpl/minimal-dpl.dpl.json"
            roles:
              - name: "internal-dpl-clock"
                connect:
                task:
                  load: minimal-dpl-internal-dpl-clock
              - name: "readout-proxy"
                connect:
                - name: "from_internal-dpl-clock_to_readout-proxy"
                  target: "{{Parent().Path}}.internal-dpl-clock:from_internal-dpl-clock_to_readout-proxy"
                  type: "pull"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: "readout-proxy"
                  target: "{{ Up(2).Path }}.stfb:dpl-chan"
                  transport: shmem
                  type: "pull"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: minimal-dpl-readout-proxy
              - name: "dpl-output-proxy"
                connect:
                - name: "from_readout-proxy_to_dpl-output-proxy"
                  target: "{{Parent().Path}}.readout-proxy:from_readout-proxy_to_dpl-output-proxy"
                  type: "pull"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: minimal-dpl-dpl-output-proxy
          - name: tof-compressor
            # generated with:
            # o2-dpl-raw-proxy -b --session default --dataspec "x:TOF/RAWDATA;dd/FLP/DISTSUBTIMEFRAME/0" --readout-proxy '--channel-config "name=readout-proxy,type=pull,method=connect,address=ipc:///tmp/stf-builder-dpl-pipe-0,transport=shmem,rateLogging=1"' \
            # | o2-tof-compressor -b --session default --tof-compressor-rdh-version 6 --tof-compressor-config "x:TOF/RAWDATA" \
            # | o2-dpl-output-proxy -b --session default --dataspec "A:TOF/CRAWDATA;dd:FLP/DISTSUBTIMEFRAME/0" --dpl-output-proxy '--channel-config "name=downstream,type=push,method=bind,address=ipc:///tmp/stf-pipe-0,rateLogging=1,transport=shmem"'
            enabled: "{{ dpl_workflow == 'tof-compressor' }}"
            defaults:
              monitoring_dpl_url: "no-op://"
              user: "flp"
              dpl_config: "/etc/flp.d/tof-compressor/tof-compressor.dpl.json"
            roles:
              - name: "internal-dpl-clock"
                connect:
                task:
                  load: tof-compressor-internal-dpl-clock
              - name: "readout-proxy"
                connect:
                - name: from_internal-dpl-clock_to_readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_readout-proxy"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ path_to_readout_proxy }}"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: tof-compressor-readout-proxy
              - name: "tof-compressor-0"
                connect:
                - name: from_readout-proxy_to_tof-compressor-0
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.readout-proxy:from_readout-proxy_to_tof-compressor-0"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: tof-compressor-tof-compressor-0
              - name: "dpl-output-proxy"
                connect:
                - name: from_readout-proxy_to_dpl-output-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.readout-proxy:from_readout-proxy_to_dpl-output-proxy"
                  rateLogging: "{{ fmq_rate_logging }}"
                - name: from_tof-compressor-0_to_dpl-output-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.tof-compressor-0:from_tof-compressor-0_to_dpl-output-proxy"
                  rateLogging: "{{ fmq_rate_logging }}"
                task:
                  load: tof-compressor-dpl-output-proxy
          - name: hmpid-raw-qc
            enabled: "{{ dpl_workflow == 'hmpid-raw-qc' }}" 
            defaults:
              monitoring_dpl_url: "no-op://"
              user: "flp"
              dpl_config: "/etc/flp.d/hmpid-raw-qc/hmpid-raw-qc.dpl.json"
              qc_config_uri: "consul-json://{{ consul_endpoint }}/o2/components/qc/ANY/any/hmpid_raw_qc-{{ it }}"
              fmq_rate_logging: 0
            roles:
              - name: "internal-dpl-clock"
                connect:
                task:
                  load: hmpid-raw-qc-internal-dpl-clock
              - name: "readout-proxy"
                connect:
                - name: from_internal-dpl-clock_to_readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_readout-proxy"
                  rateLogging: 10
                - name: readout-proxy
                  type: pull
                  transport: shmem
                  target: "{{ path_to_readout_proxy }}"
                  rateLogging: 10
                task:
                  load: hmpid-raw-qc-readout-proxy
              - name: "dpl-output-proxy"
                connect:
                - name: from_readout-proxy_to_dpl-output-proxy
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.readout-proxy:from_readout-proxy_to_dpl-output-proxy"
                  rateLogging: 10
                task:
                  load: hmpid-raw-qc-dpl-output-proxy
              - name: "Dispatcher"
                connect:
                - name: from_internal-dpl-clock_to_Dispatcher
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_Dispatcher"
                  rateLogging: 10
                - name: from_dpl-output-proxy_to_Dispatcher
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.dpl-output-proxy:from_dpl-output-proxy_to_Dispatcher"
                  rateLogging: 10
                task:
                  load: hmpid-raw-qc-Dispatcher
              - name: "QC-TASK-RUNNER-HMPIDRawTask"
                connect:
                - name: from_internal-dpl-clock_to_QC-TASK-RUNNER-HMPIDRawTask
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.internal-dpl-clock:from_internal-dpl-clock_to_QC-TASK-RUNNER-HMPIDRawTask"
                  rateLogging: 10
                - name: from_Dispatcher_to_QC-TASK-RUNNER-HMPIDRawTask
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.Dispatcher:from_Dispatcher_to_QC-TASK-RUNNER-HMPIDRawTask"
                  rateLogging: 10
                task:
                  load: hmpid-raw-qc-QC-TASK-RUNNER-HMPIDRawTask
              - name: "QC-CHECK-RUNNER-sink-QC_HMPIDRawTask-mo_0"
                connect:
                - name: from_QC-TASK-RUNNER-HMPIDRawTask_to_QC-CHECK-RUNNER-sink-QC_HMPIDRawTask-mo_0
                  type: pull
                  transport: shmem
                  target: "{{ Parent().Path }}.QC-TASK-RUNNER-HMPIDRawTask:from_QC-TASK-RUNNER-HMPIDRawTask_to_QC-CHECK-RUNNER-sink-QC_HMPIDRawTask-mo_0"
                  rateLogging: 10
                task:
                  load: hmpid-raw-qc-QC-CHECK-RUNNER-sink-QC_HMPIDRawTask-mo_0
      - name: roc-ctp-emulators
        enabled: "{{roc_ctp_emulator_enabled == 'true'}}"
        defaults:
          roc_ctp_emulator_endpoints: '["#0"]'
        roles:
          - name: "endpoint-{{ endpoint_id }}"
            for:
              range: "{{roc_ctp_emulator_endpoints}}"
              var: endpoint_id
            roles:
              - name: roc-ctp-emulator
                task:
                  load: "roc-ctp-emulator"
                  trigger: enter_RUNNING
                  timeout: 10s
                  critical: false
      - name: fairmq-shmmonitor
        enabled: "{{fmq_cleanup_enabled == 'true'}}"
        task:
          load: "fairmq-shmmonitor"
          trigger: DESTROY
          timeout: 10s
          critical: false
      - name: roc-cleanup
        enabled: "{{roc_cleanup_enabled == 'true'}}"
        task:
          load: "roc-cleanup"
          trigger: DESTROY
          timeout: 10s
          critical: false
      - name: ps-aux-on-destroy
        vars:
          shell_command: ps aux|grep OCCPlugin
        task:
          load: "shell-command"
          trigger: DESTROY
          timeout: 10s
          critical: false
  - name: odc-shim
    enabled: "{{odcshim_enabled == 'true'}}"
    task:
      load: odc-shim
  - name: dcs
    enabled: "{{dcs_enabled == 'true'}}"
    roles:
      - name: sor
        defaults:
          dcs_sor_parameters: "{\"key\":\"value\"}"
        call:
          func: dcs.StartOfRun()
          trigger: enter_RUNNING
          timeout: 5s
          critical: true
      - name: eor
        call:
          func: dcs.EndOfRun()
          trigger: leave_RUNNING
          timeout: 5s
          critical: true
  - name: dd-scheduler
    enabled: "{{ddsched_enabled == 'true'}}"
    roles:
      - name: initialize
        call:
          func: ddsched.PartitionInitialize()
          trigger: before_CONFIGURE
          timeout: 5s
          critical: true
      - name: terminate
        call:
          func: ddsched.PartitionTerminate()
          trigger: after_RESET
          timeout: 5s
          critical: true
      - name: cleanup
        call:
          func: ddsched.EnsureTermination()
          trigger: DESTROY
          timeout: 5s
          critical: false
  - name: odc
    enabled: "{{odc_enabled == 'true'}}"
    roles:
      - name: configure
        call:
          func: odc.Configure()
          trigger: before_CONFIGURE
          await: after_CONFIGURE
          timeout: 30s
          critical: true
      - name: start
        call:
          func: odc.Start()
          trigger: before_START_ACTIVITY
          await: after_START_ACTIVITY
          timeout: 5s
          critical: true
      - name: stop
        call:
          func: odc.Stop()
          trigger: before_STOP_ACTIVITY
          await: after_STOP_ACTIVITY
          timeout: 5s
          critical: true
      - name: reset
        call:
          func: odc.Reset()
          trigger: before_RESET
          await: after_RESET
          timeout: 15s
          critical: true
      - name: cleanup
        call:
          func: odc.EnsureCleanup()
          trigger: DESTROY
          timeout: 5s
          critical: false
